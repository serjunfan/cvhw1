{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3356370f-b2bd-4120-85ab-08c0a78cba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from datasets.work import make_work_transforms\n",
    "\n",
    "def box_cxcywh_to_xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=1)\n",
    "\n",
    "def rescale_bboxes(out_bbox, size):\n",
    "    img_w, img_h = size\n",
    "    b = box_cxcywh_to_xyxy(out_bbox)\n",
    "    b = b * torch.tensor([img_w, img_h,\n",
    "                          img_w, img_h\n",
    "                          ], dtype=torch.float32)\n",
    "    return b\n",
    "\n",
    "def get_images(in_path):\n",
    "    img_files = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(in_path):\n",
    "        for file in filenames:\n",
    "            filename, ext = os.path.splitext(file)\n",
    "            ext = str.lower(ext)\n",
    "            if ext == '.jpg' or ext == '.jpeg' or ext == '.gif' or ext == '.png' or ext == '.pgm':\n",
    "                img_files.append(os.path.join(dirpath, file))\n",
    "\n",
    "    return img_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23355b43-2c78-407d-bfe2-f3468d05941d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing...construction-site-build-construction-work-159306.jpeg\n",
      "before transform tagets = {'size': tensor([3072, 4608]), 'orig_size': tensor([3072, 4608])}\n",
      "after transform tagets = {'size': tensor([ 800, 1200]), 'orig_size': tensor([3072, 4608])}\n",
      "processing...construction-site-build-construction-work-159375.jpeg\n",
      "before transform tagets = {'size': tensor([3072, 4608]), 'orig_size': tensor([3072, 4608])}\n",
      "after transform tagets = {'size': tensor([ 800, 1200]), 'orig_size': tensor([3072, 4608])}\n",
      "processing...gardener-worker-gardening-machinery-162564.jpeg\n",
      "before transform tagets = {'size': tensor([2252, 3435]), 'orig_size': tensor([2252, 3435])}\n",
      "after transform tagets = {'size': tensor([ 800, 1220]), 'orig_size': tensor([2252, 3435])}\n",
      "processing...harvest-grain-combine-arable-farming-163752.jpeg\n",
      "before transform tagets = {'size': tensor([1840, 3264]), 'orig_size': tensor([1840, 3264])}\n",
      "after transform tagets = {'size': tensor([ 751, 1332]), 'orig_size': tensor([1840, 3264])}\n",
      "processing...pexels-photo-10039988.jpeg\n",
      "before transform tagets = {'size': tensor([7680, 5123]), 'orig_size': tensor([7680, 5123])}\n",
      "after transform tagets = {'size': tensor([1199,  800]), 'orig_size': tensor([7680, 5123])}\n",
      "processing...pexels-photo-10040003.jpeg\n",
      "before transform tagets = {'size': tensor([7138, 5072]), 'orig_size': tensor([7138, 5072])}\n",
      "after transform tagets = {'size': tensor([1125,  800]), 'orig_size': tensor([7138, 5072])}\n",
      "processing...pexels-photo-10084716.jpeg\n",
      "before transform tagets = {'size': tensor([5461, 8192]), 'orig_size': tensor([5461, 8192])}\n",
      "after transform tagets = {'size': tensor([ 800, 1200]), 'orig_size': tensor([5461, 8192])}\n",
      "processing...pexels-photo-10088317.jpeg\n",
      "before transform tagets = {'size': tensor([5472, 3648]), 'orig_size': tensor([5472, 3648])}\n",
      "after transform tagets = {'size': tensor([1200,  800]), 'orig_size': tensor([5472, 3648])}\n",
      "processing...pexels-photo-10130754.jpeg\n",
      "before transform tagets = {'size': tensor([4016, 6016]), 'orig_size': tensor([4016, 6016])}\n",
      "after transform tagets = {'size': tensor([ 800, 1198]), 'orig_size': tensor([4016, 6016])}\n",
      "processing...pexels-photo-1018565.jpeg\n",
      "before transform tagets = {'size': tensor([2000, 1335]), 'orig_size': tensor([2000, 1335])}\n",
      "after transform tagets = {'size': tensor([1198,  800]), 'orig_size': tensor([2000, 1335])}\n",
      "processing...pexels-photo-1018568.jpeg\n",
      "before transform tagets = {'size': tensor([1214, 2000]), 'orig_size': tensor([1214, 2000])}\n",
      "after transform tagets = {'size': tensor([ 800, 1317]), 'orig_size': tensor([1214, 2000])}\n",
      "processing...pexels-photo-10202856.jpeg\n",
      "before transform tagets = {'size': tensor([3733, 5614]), 'orig_size': tensor([3733, 5614])}\n",
      "after transform tagets = {'size': tensor([ 800, 1203]), 'orig_size': tensor([3733, 5614])}\n",
      "processing...pexels-photo-10316634.jpeg\n",
      "before transform tagets = {'size': tensor([2832, 4256]), 'orig_size': tensor([2832, 4256])}\n",
      "after transform tagets = {'size': tensor([ 800, 1202]), 'orig_size': tensor([2832, 4256])}\n",
      "processing...pexels-photo-10341105.jpeg\n",
      "before transform tagets = {'size': tensor([3019, 4499]), 'orig_size': tensor([3019, 4499])}\n",
      "after transform tagets = {'size': tensor([ 800, 1192]), 'orig_size': tensor([3019, 4499])}\n",
      "processing...pexels-photo-10341110.jpeg\n",
      "before transform tagets = {'size': tensor([4680, 3132]), 'orig_size': tensor([4680, 3132])}\n",
      "after transform tagets = {'size': tensor([1195,  800]), 'orig_size': tensor([4680, 3132])}\n",
      "processing...pexels-photo-10341121.jpeg\n",
      "before transform tagets = {'size': tensor([4160, 6240]), 'orig_size': tensor([4160, 6240])}\n",
      "after transform tagets = {'size': tensor([ 800, 1200]), 'orig_size': tensor([4160, 6240])}\n",
      "processing...pexels-photo-10347138.jpeg\n",
      "before transform tagets = {'size': tensor([4160, 6240]), 'orig_size': tensor([4160, 6240])}\n",
      "after transform tagets = {'size': tensor([ 800, 1200]), 'orig_size': tensor([4160, 6240])}\n",
      "processing...pexels-photo-10347168.jpeg\n",
      "before transform tagets = {'size': tensor([6116, 4084]), 'orig_size': tensor([6116, 4084])}\n",
      "after transform tagets = {'size': tensor([1198,  800]), 'orig_size': tensor([6116, 4084])}\n",
      "processing...pexels-photo-10375935.jpeg\n",
      "before transform tagets = {'size': tensor([4480, 6720]), 'orig_size': tensor([4480, 6720])}\n",
      "after transform tagets = {'size': tensor([ 800, 1200]), 'orig_size': tensor([4480, 6720])}\n",
      "processing...pexels-photo-10375949.jpeg\n",
      "before transform tagets = {'size': tensor([4076, 6113]), 'orig_size': tensor([4076, 6113])}\n",
      "after transform tagets = {'size': tensor([ 800, 1199]), 'orig_size': tensor([4076, 6113])}\n",
      "processing...pexels-photo-10376161.jpeg\n",
      "before transform tagets = {'size': tensor([4307, 6460]), 'orig_size': tensor([4307, 6460])}\n",
      "after transform tagets = {'size': tensor([ 800, 1199]), 'orig_size': tensor([4307, 6460])}\n",
      "processing...pexels-photo-10402665.jpeg\n",
      "before transform tagets = {'size': tensor([5437, 3664]), 'orig_size': tensor([5437, 3664])}\n",
      "after transform tagets = {'size': tensor([1187,  800]), 'orig_size': tensor([5437, 3664])}\n",
      "processing...pexels-photo-1045204.jpeg\n",
      "before transform tagets = {'size': tensor([3456, 5184]), 'orig_size': tensor([3456, 5184])}\n",
      "after transform tagets = {'size': tensor([ 800, 1200]), 'orig_size': tensor([3456, 5184])}\n",
      "processing...pexels-photo-1046212.jpeg\n",
      "before transform tagets = {'size': tensor([2072, 2989]), 'orig_size': tensor([2072, 2989])}\n",
      "after transform tagets = {'size': tensor([ 800, 1154]), 'orig_size': tensor([2072, 2989])}\n",
      "processing...pexels-photo-10474856.jpeg\n",
      "before transform tagets = {'size': tensor([4480, 6720]), 'orig_size': tensor([4480, 6720])}\n",
      "after transform tagets = {'size': tensor([ 800, 1200]), 'orig_size': tensor([4480, 6720])}\n",
      "processing...pexels-photo-1049691.jpeg\n",
      "before transform tagets = {'size': tensor([4800, 7200]), 'orig_size': tensor([4800, 7200])}\n",
      "after transform tagets = {'size': tensor([ 800, 1200]), 'orig_size': tensor([4800, 7200])}\n",
      "processing...pexels-photo-10573466.png\n",
      "before transform tagets = {'size': tensor([5184, 3456]), 'orig_size': tensor([5184, 3456])}\n",
      "after transform tagets = {'size': tensor([1200,  800]), 'orig_size': tensor([5184, 3456])}\n",
      "processing...pexels-photo-10609091.jpeg\n",
      "before transform tagets = {'size': tensor([5462, 8192]), 'orig_size': tensor([5462, 8192])}\n",
      "after transform tagets = {'size': tensor([ 800, 1199]), 'orig_size': tensor([5462, 8192])}\n",
      "processing...pexels-photo-10615318.jpeg\n",
      "before transform tagets = {'size': tensor([5119, 7675]), 'orig_size': tensor([5119, 7675])}\n",
      "after transform tagets = {'size': tensor([ 800, 1199]), 'orig_size': tensor([5119, 7675])}\n",
      "processing...pexels-photo-10615322.jpeg\n",
      "before transform tagets = {'size': tensor([5304, 7952]), 'orig_size': tensor([5304, 7952])}\n",
      "after transform tagets = {'size': tensor([ 800, 1199]), 'orig_size': tensor([5304, 7952])}\n",
      "processing...pexels-photo-10676692.jpeg\n",
      "before transform tagets = {'size': tensor([6000, 4000]), 'orig_size': tensor([6000, 4000])}\n",
      "after transform tagets = {'size': tensor([1200,  800]), 'orig_size': tensor([6000, 4000])}\n",
      "processing...pexels-photo-10826406.jpeg\n",
      "before transform tagets = {'size': tensor([3444, 5144]), 'orig_size': tensor([3444, 5144])}\n",
      "after transform tagets = {'size': tensor([ 800, 1194]), 'orig_size': tensor([3444, 5144])}\n",
      "processing...pexels-photo-10841934.jpeg\n",
      "before transform tagets = {'size': tensor([4310, 3448]), 'orig_size': tensor([4310, 3448])}\n",
      "after transform tagets = {'size': tensor([1000,  800]), 'orig_size': tensor([4310, 3448])}\n",
      "processing...pexels-photo-11010354.jpeg\n",
      "before transform tagets = {'size': tensor([4928, 3264]), 'orig_size': tensor([4928, 3264])}\n",
      "after transform tagets = {'size': tensor([1207,  800]), 'orig_size': tensor([4928, 3264])}\n",
      "processing...pexels-photo-1103063.jpeg\n",
      "before transform tagets = {'size': tensor([2997, 4496]), 'orig_size': tensor([2997, 4496])}\n",
      "after transform tagets = {'size': tensor([ 800, 1200]), 'orig_size': tensor([2997, 4496])}\n",
      "processing...pexels-photo-11117849.jpeg\n",
      "before transform tagets = {'size': tensor([3333, 5000]), 'orig_size': tensor([3333, 5000])}\n",
      "after transform tagets = {'size': tensor([ 800, 1200]), 'orig_size': tensor([3333, 5000])}\n",
      "processing...pexels-photo-11139140.jpeg\n",
      "before transform tagets = {'size': tensor([2388, 1910]), 'orig_size': tensor([2388, 1910])}\n",
      "after transform tagets = {'size': tensor([1000,  800]), 'orig_size': tensor([2388, 1910])}\n",
      "processing...pexels-photo-1115187.jpeg\n",
      "before transform tagets = {'size': tensor([3712, 5568]), 'orig_size': tensor([3712, 5568])}\n",
      "after transform tagets = {'size': tensor([ 800, 1200]), 'orig_size': tensor([3712, 5568])}\n",
      "processing...pexels-photo-1115358.jpeg\n",
      "before transform tagets = {'size': tensor([3712, 5568]), 'orig_size': tensor([3712, 5568])}\n",
      "after transform tagets = {'size': tensor([ 800, 1200]), 'orig_size': tensor([3712, 5568])}\n",
      "processing...pexels-photo-1117452.jpeg\n",
      "before transform tagets = {'size': tensor([2482, 3409]), 'orig_size': tensor([2482, 3409])}\n",
      "after transform tagets = {'size': tensor([ 800, 1098]), 'orig_size': tensor([2482, 3409])}\n",
      "processing...pexels-photo-11194902.jpeg\n",
      "before transform tagets = {'size': tensor([3407, 5111]), 'orig_size': tensor([3407, 5111])}\n",
      "after transform tagets = {'size': tensor([ 800, 1200]), 'orig_size': tensor([3407, 5111])}\n",
      "processing...pexels-photo-11213214.jpeg\n",
      "before transform tagets = {'size': tensor([3510, 6240]), 'orig_size': tensor([3510, 6240])}\n",
      "after transform tagets = {'size': tensor([ 750, 1333]), 'orig_size': tensor([3510, 6240])}\n",
      "processing...pexels-photo-11280956.jpeg\n",
      "before transform tagets = {'size': tensor([3456, 5184]), 'orig_size': tensor([3456, 5184])}\n",
      "after transform tagets = {'size': tensor([ 800, 1200]), 'orig_size': tensor([3456, 5184])}\n",
      "processing...pexels-photo-11293626.jpeg\n",
      "before transform tagets = {'size': tensor([6000, 4000]), 'orig_size': tensor([6000, 4000])}\n",
      "after transform tagets = {'size': tensor([1200,  800]), 'orig_size': tensor([6000, 4000])}\n",
      "processing...pexels-photo-11349965.jpeg\n",
      "before transform tagets = {'size': tensor([2864, 2299]), 'orig_size': tensor([2864, 2299])}\n",
      "after transform tagets = {'size': tensor([996, 800]), 'orig_size': tensor([2864, 2299])}\n",
      "processing...pexels-photo-11427405.jpeg\n",
      "before transform tagets = {'size': tensor([4000, 6000]), 'orig_size': tensor([4000, 6000])}\n",
      "after transform tagets = {'size': tensor([ 800, 1200]), 'orig_size': tensor([4000, 6000])}\n",
      "processing...pexels-photo-11467876.jpeg\n",
      "before transform tagets = {'size': tensor([3000, 4501]), 'orig_size': tensor([3000, 4501])}\n",
      "after transform tagets = {'size': tensor([ 800, 1200]), 'orig_size': tensor([3000, 4501])}\n",
      "processing...pexels-photo-11486454.jpeg\n",
      "before transform tagets = {'size': tensor([3379, 4506]), 'orig_size': tensor([3379, 4506])}\n",
      "after transform tagets = {'size': tensor([ 800, 1066]), 'orig_size': tensor([3379, 4506])}\n",
      "processing...pexels-photo-11554087.jpeg\n",
      "before transform tagets = {'size': tensor([3041, 2027]), 'orig_size': tensor([3041, 2027])}\n",
      "after transform tagets = {'size': tensor([1200,  800]), 'orig_size': tensor([3041, 2027])}\n",
      "processing...pexels-photo-11565004.jpeg\n",
      "before transform tagets = {'size': tensor([4000, 3000]), 'orig_size': tensor([4000, 3000])}\n",
      "after transform tagets = {'size': tensor([1066,  800]), 'orig_size': tensor([4000, 3000])}\n",
      "processing...pexels-photo-11580897.jpeg\n",
      "before transform tagets = {'size': tensor([3456, 2304]), 'orig_size': tensor([3456, 2304])}\n",
      "after transform tagets = {'size': tensor([1200,  800]), 'orig_size': tensor([3456, 2304])}\n",
      "processing...pexels-photo-11586646.jpeg\n",
      "before transform tagets = {'size': tensor([3872, 2592]), 'orig_size': tensor([3872, 2592])}\n",
      "after transform tagets = {'size': tensor([1195,  800]), 'orig_size': tensor([3872, 2592])}\n",
      "processing...pexels-photo-11765530.jpeg\n",
      "before transform tagets = {'size': tensor([2488, 3316]), 'orig_size': tensor([2488, 3316])}\n",
      "after transform tagets = {'size': tensor([ 800, 1066]), 'orig_size': tensor([2488, 3316])}\n",
      "processing...pexels-photo-11779230.jpeg\n",
      "before transform tagets = {'size': tensor([3000, 4000]), 'orig_size': tensor([3000, 4000])}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 15\u001b[0m\n\u001b[0;32m     10\u001b[0m dummy_target \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mas_tensor([\u001b[38;5;28mint\u001b[39m(h), \u001b[38;5;28mint\u001b[39m(w)]),\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morig_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mas_tensor([\u001b[38;5;28mint\u001b[39m(h), \u001b[38;5;28mint\u001b[39m(w)])\n\u001b[0;32m     13\u001b[0m }\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore transform tagets = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(dummy_target))\n\u001b[1;32m---> 15\u001b[0m image, targets \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43morig_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter transform tagets = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(targets))\n",
      "File \u001b[1;32m~\\cv\\detr\\datasets\\transforms.py:267\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, image, target)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, image, target):\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m--> 267\u001b[0m         image, target \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image, target\n",
      "File \u001b[1;32m~\\cv\\detr\\datasets\\transforms.py:199\u001b[0m, in \u001b[0;36mRandomResize.__call__\u001b[1;34m(self, img, target)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img, target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    198\u001b[0m     size \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msizes)\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\cv\\detr\\datasets\\transforms.py:106\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(image, target, size, max_size)\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m get_size_with_aspect_ratio(image_size, size, max_size)\n\u001b[0;32m    105\u001b[0m size \u001b[38;5;241m=\u001b[39m get_size(image\u001b[38;5;241m.\u001b[39msize, size, max_size)\n\u001b[1;32m--> 106\u001b[0m rescaled_image \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rescaled_image, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cv\\Lib\\site-packages\\torchvision\\transforms\\functional.py:477\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[0;32m    475\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    476\u001b[0m     pil_interpolation \u001b[38;5;241m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[1;32m--> 477\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_interpolation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39moutput_size, interpolation\u001b[38;5;241m=\u001b[39minterpolation\u001b[38;5;241m.\u001b[39mvalue, antialias\u001b[38;5;241m=\u001b[39mantialias)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cv\\Lib\\site-packages\\torchvision\\transforms\\_functional_pil.py:250\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(img, size, interpolation)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot inappropriate size arg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cv\\Lib\\site-packages\\PIL\\Image.py:2293\u001b[0m, in \u001b[0;36mImage.resize\u001b[1;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[0;32m   2290\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreducing_gap must be 1.0 or greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m-> 2293\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m box \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2295\u001b[0m     box \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cv\\Lib\\site-packages\\PIL\\ImageFile.py:293\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    292\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 293\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path = '../datasets/valid/images'\n",
    "img_path = get_images(path)\n",
    "\n",
    "for img_sample in img_path:\n",
    "    filename = os.path.basename(img_sample)\n",
    "    print(\"processing...{}\".format(filename))\n",
    "    orig_image = Image.open(img_sample)\n",
    "    w, h = orig_image.size\n",
    "    transform = make_work_transforms(\"val\")\n",
    "    dummy_target = {\n",
    "        \"size\": torch.as_tensor([int(h), int(w)]),\n",
    "        \"orig_size\": torch.as_tensor([int(h), int(w)])\n",
    "    }\n",
    "    print('before transform tagets = {}'.format(dummy_target))\n",
    "    image, targets = transform(orig_image, dummy_target)\n",
    "    print('after transform tagets = {}'.format(targets))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
